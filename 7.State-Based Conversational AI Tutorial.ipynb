{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1696,
     "status": "ok",
     "timestamp": 1765818903212,
     "user": {
      "displayName": "Bùi Tuấn Dũng",
      "userId": "00145197728970441747"
     },
     "user_tz": -420
    },
    "id": "OuPuhxtGo7bo"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.graph import StateGraph, START , END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model=ChatGoogleGenerativeAI(\n",
    "    model='gemini-2.5-flash'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    message: List[HumanMessage]\n",
    "\n",
    "def process_message(state: AgentState) -> AgentState:\n",
    "    model_response = model.invoke(state['message'])\n",
    "    state['message'].append(model_response)\n",
    "    print(f\"Agent response: {model_response}\")\n",
    "    print('\\n\\n')\n",
    "    return state\n",
    "\n",
    "def end(state: AgentState) -> AgentState:\n",
    "    return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x12879ddf0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node('process_message', process_message)\n",
    "\n",
    "graph.add_edge(START, 'process_message')\n",
    "graph.add_edge('process_message', END)\n",
    "\n",
    "bot = graph.compile()\n",
    "\n",
    "bot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.0-flash-exp' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\nPlease retry in 59.826837118s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '59s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2958\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2957\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2958\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2959\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2960\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2961\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/models.py:5230\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5229\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5230\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5232\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5234\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/models.py:4012\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4010\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4012\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4013\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   4014\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4017\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4018\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1385\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m response_body = (\n\u001b[32m   1390\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1194\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m     method=http_request.method,\n\u001b[32m   1196\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/google/genai/errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\nPlease retry in 59.826837118s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '59s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m agent_input = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m: [HumanMessage(content=\u001b[33m'\u001b[39m\u001b[33mHello, how are you?\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mbot\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mprocess_message\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess_message\u001b[39m(state: AgentState) -> AgentState:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     model_response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     state[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m].append(model_response)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAgent response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2461\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2458\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2459\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:2962\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   2958\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   2959\u001b[39m         **request,\n\u001b[32m   2960\u001b[39m     )\n\u001b[32m   2961\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2962\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/LangGraph/venv/lib/python3.12/site-packages/langchain_google_genai/chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.0-flash-exp' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash-exp\\nPlease retry in 59.826837118s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '59s'}]}}",
      "During task with name 'process_message' and id '19db836b-f24c-c684-9481-aa91ecba57a6'"
     ]
    }
   ],
   "source": [
    "agent_input = {\n",
    "    'message': [HumanMessage(content='Hello, how are you?')]\n",
    "}\n",
    "\n",
    "response = bot.invoke(agent_input)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPdODhCcD0x/oNqVgUSQmZC",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (LangGraph)",
   "language": "python",
   "name": "langgraph-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
